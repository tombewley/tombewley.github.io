---
title: Transformer
permalink: /notes/Transformer
---

The term "transformer" doesn't have a fully precise definition, but in general is used to refer to any neural sequence-to-sequence model where the *only* interaction between instances is through [attention](Attention). They also make use of basic feedforward layers with nonlinear activations, where a lot of the representational heavy lifting happens, and layer normalisation.

added to residual stream, "shared memory"

causal attention